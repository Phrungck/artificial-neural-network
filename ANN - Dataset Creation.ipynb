{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3486, 354)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mounting the given dataset file\n",
    "dataset = np.genfromtxt('data.csv', delimiter=',')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3486,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mounting the given datalabel file\n",
    "data_labels = np.genfromtxt('data_labels.csv', delimiter = ',', dtype='int')\n",
    "data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({8: 466, 5: 287, 1: 1625, 6: 310, 4: 483, 2: 233, 3: 30, 7: 52})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the imbalance in data\n",
    "Counter(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling and undersampling using SMOTE\n",
    "oversampling = SMOTE(sampling_strategy={8.0: 1400,\n",
    "         5.0: 1400,\n",
    "         6.0: 1400,\n",
    "         4.0: 1400,\n",
    "         2.0: 1400,\n",
    "         3.0: 1400,\n",
    "         7.0: 1400})\n",
    "undersampling = RandomUnderSampler(sampling_strategy={\n",
    "         1.0: 1400,})\n",
    "steps = [('over',oversampling),('u',undersampling)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "dataset, data_labels = pipeline.fit_resample(dataset, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1400,\n",
       "         2: 1400,\n",
       "         3: 1400,\n",
       "         4: 1400,\n",
       "         5: 1400,\n",
       "         6: 1400,\n",
       "         7: 1400,\n",
       "         8: 1400})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the oversampled and undersampled data labels\n",
    "Counter(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11200, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshaping to allow concatenation\n",
    "labels = data_labels.reshape(-1,1)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating and saving the dataset and labels\n",
    "full_dataset = np.concatenate((dataset,labels),axis=1)\n",
    "np.savetxt('full_dataset.csv', full_dataset, delimiter=',')\n",
    "full_dataset[:10,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffling the ordered final dataset\n",
    "np.random.shuffle(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into three sets\n",
    "training_set, validation_set, testing_set = np.split(full_dataset, [int(.6 * len(full_dataset)), int(.8 * len(full_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the sets\n",
    "training_labels = training_set[:,-1]\n",
    "np.savetxt('training_labels.csv', training_labels, delimiter=',')\n",
    "\n",
    "training = np.delete(training_set, -1, axis=1)\n",
    "np.savetxt('training_set.csv', training, delimiter=',')\n",
    "\n",
    "validation_labels = validation_set[:,-1]\n",
    "np.savetxt('validation_labels.csv', validation_labels, delimiter=',')\n",
    "\n",
    "validation = np.delete(validation_set, -1, axis=1)\n",
    "np.savetxt('validation_set.csv', validation,delimiter=',')\n",
    "\n",
    "testing_labels = testing_set[:,-1]\n",
    "np.savetxt('test_labels.csv',testing_labels, delimiter=',')\n",
    "\n",
    "testing = np.delete(testing_set, -1, axis=1)\n",
    "np.savetxt('test_set.csv', testing, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
